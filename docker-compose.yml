services:
  redis:
    image: redis:alpine
    ports:
      - "6379:6379"
    command: redis-server --maxmemory 512mb --maxmemory-policy allkeys-lru
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  api:
    platform: linux/amd64
    build:
      context: .
      dockerfile: ./backend/Dockerfile
    volumes:
      - ./backend/app/ml_models:/app/app/ml_models
      - ./backend/logs:/app/logs
      - ./alvaDescCLI:/app/backend/app/ml_models/alvaDescCLI
    env_file:
      - ./backend/.env
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
      - MODEL_CLASSIFIER_PATH=/app/app/ml_models/model_mtb.json
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  worker:
    platform: linux/amd64
    build:
      context: .
      dockerfile: ./backend/Dockerfile
    volumes:
      - ./backend/app/ml_models:/app/app/ml_models
      - ./backend/logs:/app/logs
      - ./alvaDescCLI:/app/backend/app/ml_models/alvaDescCLI
    env_file:
      - ./backend/.env
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
      - MODEL_CLASSIFIER_PATH=/app/app/ml_models/model_mtb.json
    command: celery -A app.worker.celery_app worker --loglevel=debug
    mem_limit: 2g
    depends_on:
      redis:
        condition: service_healthy

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      args:
        - BACKEND_URL=http://api:8000
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_GRAPHQL_ENDPOINT=http://api:8000/graphql
      - BACKEND_URL=http://api:8000
    depends_on:
      api:
        condition: service_healthy
